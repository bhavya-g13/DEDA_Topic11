{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98417e16",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c2247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pypfopt.plotting as plotting\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import discrete_allocation\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import objective_functions\n",
    "from pypfopt import base_optimizer\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation\n",
    "from pypfopt.hierarchical_portfolio import HRPOpt\n",
    "\n",
    "from custom_allocation import CustomDiscreteAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4279ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM\n",
      "AOS\n",
      "ABT\n",
      "ABBV\n",
      "ACN\n",
      "ATVI\n",
      "ADM\n",
      "ADBE\n",
      "ADP\n",
      "AAP\n",
      "AES\n",
      "AFL\n",
      "A\n",
      "APD\n",
      "AKAM\n",
      "ALK\n",
      "ALB\n",
      "ARE\n",
      "ALGN\n",
      "ALLE\n",
      "LNT\n",
      "ALL\n",
      "GOOGL\n",
      "GOOG\n",
      "MO\n",
      "AMZN\n",
      "AMCR\n",
      "AMD\n",
      "AEE\n",
      "AAL\n",
      "AEP\n",
      "AXP\n",
      "AIG\n",
      "AMT\n",
      "AWK\n",
      "AMP\n",
      "ABC\n",
      "AME\n",
      "AMGN\n",
      "APH\n",
      "ADI\n",
      "ANSS\n",
      "AON\n",
      "APA\n",
      "AAPL\n",
      "AMAT\n",
      "APTV\n",
      "ACGL\n",
      "ANET\n",
      "AJG\n",
      "AIZ\n",
      "T\n",
      "ATO\n",
      "ADSK\n",
      "AZO\n",
      "AVB\n",
      "AVY\n",
      "AXON\n",
      "BKR\n",
      "BALL\n",
      "BAC\n",
      "BBWI\n",
      "BAX\n",
      "BDX\n",
      "WRB\n",
      "BRK.B\n",
      "BBY\n",
      "BIO\n",
      "TECH\n",
      "BIIB\n",
      "BLK\n",
      "BK\n",
      "BA\n",
      "BKNG\n",
      "BWA\n",
      "BXP\n",
      "BSX\n",
      "BMY\n",
      "AVGO\n",
      "BR\n",
      "BRO\n",
      "BF.B\n",
      "BG\n",
      "CHRW\n",
      "CDNS\n",
      "CZR\n",
      "CPT\n",
      "CPB\n",
      "COF\n",
      "CAH\n",
      "KMX\n",
      "CCL\n",
      "CARR\n",
      "CTLT\n",
      "CAT\n",
      "CBOE\n",
      "CBRE\n",
      "CDW\n",
      "CE\n",
      "CNC\n",
      "CNP\n",
      "CDAY\n",
      "CF\n",
      "CRL\n",
      "SCHW\n",
      "CHTR\n",
      "CVX\n",
      "CMG\n",
      "CB\n",
      "CHD\n",
      "CI\n",
      "CINF\n",
      "CTAS\n",
      "CSCO\n",
      "C\n",
      "CFG\n",
      "CLX\n",
      "CME\n",
      "CMS\n",
      "KO\n",
      "CTSH\n",
      "CL\n",
      "CMCSA\n",
      "CMA\n",
      "CAG\n",
      "COP\n",
      "ED\n",
      "STZ\n",
      "CEG\n",
      "COO\n",
      "CPRT\n",
      "GLW\n",
      "CTVA\n",
      "CSGP\n",
      "COST\n",
      "CTRA\n",
      "CCI\n",
      "CSX\n",
      "CMI\n",
      "CVS\n",
      "DHI\n",
      "DHR\n",
      "DRI\n",
      "DVA\n",
      "DE\n",
      "DAL\n",
      "XRAY\n",
      "DVN\n",
      "DXCM\n",
      "FANG\n",
      "DLR\n",
      "DFS\n",
      "DIS\n",
      "DG\n",
      "DLTR\n",
      "D\n",
      "DPZ\n",
      "DOV\n",
      "DOW\n",
      "DTE\n",
      "DUK\n",
      "DD\n",
      "DXC\n",
      "EMN\n",
      "ETN\n",
      "EBAY\n",
      "ECL\n",
      "EIX\n",
      "EW\n",
      "EA\n",
      "ELV\n",
      "LLY\n",
      "EMR\n",
      "ENPH\n",
      "ETR\n",
      "EOG\n",
      "EPAM\n",
      "EQT\n",
      "EFX\n",
      "EQIX\n",
      "EQR\n",
      "ESS\n",
      "EL\n",
      "ETSY\n",
      "RE\n",
      "EVRG\n",
      "ES\n",
      "EXC\n",
      "EXPE\n",
      "EXPD\n",
      "EXR\n",
      "XOM\n",
      "FFIV\n",
      "FDS\n",
      "FICO\n",
      "FAST\n",
      "FRT\n",
      "FDX\n",
      "FITB\n",
      "FSLR\n",
      "FE\n",
      "FIS\n",
      "FI\n",
      "FLT\n",
      "FMC\n",
      "F\n",
      "FTNT\n",
      "FTV\n",
      "FOXA\n",
      "FOX\n",
      "BEN\n",
      "FCX\n",
      "GRMN\n",
      "IT\n",
      "GEHC\n",
      "GEN\n",
      "GNRC\n",
      "GD\n",
      "GE\n",
      "GIS\n",
      "GM\n",
      "GPC\n",
      "GILD\n",
      "GL\n",
      "GPN\n",
      "GS\n",
      "HAL\n",
      "HIG\n",
      "HAS\n",
      "HCA\n",
      "PEAK\n",
      "HSIC\n",
      "HSY\n",
      "HES\n",
      "HPE\n",
      "HLT\n",
      "HOLX\n",
      "HD\n",
      "HON\n",
      "HRL\n",
      "HST\n",
      "HWM\n",
      "HPQ\n",
      "HUM\n",
      "HBAN\n",
      "HII\n",
      "IBM\n",
      "IEX\n",
      "IDXX\n",
      "ITW\n",
      "ILMN\n",
      "INCY\n",
      "IR\n",
      "PODD\n",
      "INTC\n",
      "ICE\n",
      "IFF\n",
      "IP\n",
      "IPG\n",
      "INTU\n",
      "ISRG\n",
      "IVZ\n",
      "INVH\n",
      "IQV\n",
      "IRM\n",
      "JBHT\n",
      "JKHY\n",
      "J\n",
      "JNJ\n",
      "JCI\n",
      "JPM\n",
      "JNPR\n",
      "K\n",
      "KDP\n",
      "KEY\n",
      "KEYS\n",
      "KMB\n",
      "KIM\n",
      "KMI\n",
      "KLAC\n",
      "KHC\n",
      "KR\n",
      "LHX\n",
      "LH\n",
      "LRCX\n",
      "LW\n",
      "LVS\n",
      "LDOS\n",
      "LEN\n",
      "LNC\n",
      "LIN\n",
      "LYV\n",
      "LKQ\n",
      "LMT\n",
      "L\n",
      "LOW\n",
      "LYB\n",
      "MTB\n",
      "MRO\n",
      "MPC\n",
      "MKTX\n",
      "MAR\n",
      "MMC\n",
      "MLM\n",
      "MAS\n",
      "MA\n",
      "MTCH\n",
      "MKC\n",
      "MCD\n",
      "MCK\n",
      "MDT\n",
      "MRK\n",
      "META\n",
      "MET\n",
      "MTD\n",
      "MGM\n",
      "MCHP\n",
      "MU\n",
      "MSFT\n",
      "MAA\n",
      "MRNA\n",
      "MHK\n",
      "MOH\n",
      "TAP\n",
      "MDLZ\n",
      "MPWR\n",
      "MNST\n",
      "MCO\n",
      "MS\n",
      "MOS\n",
      "MSI\n",
      "MSCI\n",
      "NDAQ\n",
      "NTAP\n",
      "NFLX\n",
      "NWL\n",
      "NEM\n",
      "NWSA\n",
      "NWS\n",
      "NEE\n",
      "NKE\n",
      "NI\n",
      "NDSN\n",
      "NSC\n",
      "NTRS\n",
      "NOC\n",
      "NCLH\n",
      "NRG\n",
      "NUE\n",
      "NVDA\n",
      "NVR\n",
      "NXPI\n",
      "ORLY\n",
      "OXY\n",
      "ODFL\n",
      "OMC\n",
      "ON\n",
      "OKE\n",
      "ORCL\n",
      "OGN\n",
      "OTIS\n",
      "PCAR\n",
      "PKG\n",
      "PANW\n",
      "PARA\n",
      "PH\n",
      "PAYX\n",
      "PAYC\n",
      "PYPL\n",
      "PNR\n",
      "PEP\n",
      "PFE\n",
      "PCG\n",
      "PM\n",
      "PSX\n",
      "PNW\n",
      "PXD\n",
      "PNC\n",
      "POOL\n",
      "PPG\n",
      "PPL\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PLD\n",
      "PRU\n",
      "PEG\n",
      "PTC\n",
      "PSA\n",
      "PHM\n",
      "QRVO\n",
      "PWR\n",
      "QCOM\n",
      "DGX\n",
      "RL\n",
      "RJF\n",
      "RTX\n",
      "O\n",
      "REG\n",
      "REGN\n",
      "RF\n",
      "RSG\n",
      "RMD\n",
      "RVTY\n",
      "RHI\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RCL\n",
      "SPGI\n",
      "CRM\n",
      "SBAC\n",
      "SLB\n",
      "STX\n",
      "SEE\n",
      "SRE\n",
      "NOW\n",
      "SHW\n",
      "SPG\n",
      "SWKS\n",
      "SJM\n",
      "SNA\n",
      "SEDG\n",
      "SO\n",
      "LUV\n",
      "SWK\n",
      "SBUX\n",
      "STT\n",
      "STLD\n",
      "STE\n",
      "SYK\n",
      "SYF\n",
      "SNPS\n",
      "SYY\n",
      "TMUS\n",
      "TROW\n",
      "TTWO\n",
      "TPR\n",
      "TRGP\n",
      "TGT\n",
      "TEL\n",
      "TDY\n",
      "TFX\n",
      "TER\n",
      "TSLA\n",
      "TXN\n",
      "TXT\n",
      "TMO\n",
      "TJX\n",
      "TSCO\n",
      "TT\n",
      "TDG\n",
      "TRV\n",
      "TRMB\n",
      "TFC\n",
      "TYL\n",
      "TSN\n",
      "USB\n",
      "UDR\n",
      "ULTA\n",
      "UNP\n",
      "UAL\n",
      "UPS\n",
      "URI\n",
      "UNH\n",
      "UHS\n",
      "VLO\n",
      "VTR\n",
      "VRSN\n",
      "VRSK\n",
      "VZ\n",
      "VRTX\n",
      "VFC\n",
      "VTRS\n",
      "VICI\n",
      "V\n",
      "VMC\n",
      "WAB\n",
      "WBA\n",
      "WMT\n",
      "WBD\n",
      "WM\n",
      "WAT\n",
      "WEC\n",
      "WFC\n",
      "WELL\n",
      "WST\n",
      "WDC\n",
      "WRK\n",
      "WY\n",
      "WHR\n",
      "WMB\n",
      "WTW\n",
      "GWW\n",
      "WYNN\n",
      "XEL\n",
      "XYL\n",
      "YUM\n",
      "ZBRA\n",
      "ZBH\n",
      "ZION\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page containing the S&P 500 components\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Send a GET request to the URL and get the page content\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Find the table containing the stock data\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Iterate over the rows and extract the stock symbols\n",
    "sp500_stocks = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    stock_symbol = cells[0].text.strip()\n",
    "    sp500_stocks.append(stock_symbol)\n",
    "\n",
    "# Print the list of S&P 500 stocks\n",
    "for stock in sp500_stocks:\n",
    "    print(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cf4e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp500_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61dda939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVS\n",
      "IT\n",
      "ITW\n",
      "GLW\n",
      "ANSS\n",
      "D\n",
      "ENPH\n",
      "AFL\n",
      "AME\n",
      "IEX\n",
      "ATVI\n",
      "BKR\n",
      "DAL\n",
      "SLB\n",
      "BAC\n",
      "WRK\n",
      "DTE\n",
      "TTWO\n",
      "PPL\n",
      "NDAQ\n",
      "ALGN\n",
      "ULTA\n",
      "MAA\n",
      "AWK\n",
      "BIIB\n",
      "ROP\n",
      "USB\n",
      "PNC\n",
      "AVGO\n",
      "CB\n",
      "SYY\n",
      "PHM\n",
      "PAYC\n",
      "GIS\n",
      "AMGN\n",
      "MET\n",
      "FOXA\n",
      "BKNG\n",
      "ORCL\n",
      "AAL\n",
      "VRTX\n",
      "ALB\n",
      "COF\n",
      "ETN\n",
      "CEG\n",
      "EL\n",
      "RTX\n",
      "PFE\n",
      "WMB\n",
      "EMN\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(45)\n",
    "\n",
    "# Generate random selection of 20 stocks\n",
    "random_stocks = random.sample(sp500_stocks, 50)\n",
    "\n",
    "# Print the randomly selected stocks\n",
    "for stock in random_stocks:\n",
    "    print(stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8531d3d",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d575319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker CVS: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker IT: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ITW: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker GLW: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ANSS: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker D: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ENPH: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AFL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AME: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker IEX: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ATVI: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker BKR: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker DAL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker SLB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker BAC: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker WRK: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker DTE: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker TTWO: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker PPL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker NDAQ: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ALGN: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ULTA: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker MAA: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AWK: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker BIIB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ROP: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker USB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker PNC: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AVGO: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker CB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker SYY: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker PHM: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker PAYC: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker GIS: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AMGN: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker MET: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker FOXA: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker BKNG: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ORCL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker AAL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker VRTX: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ALB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker COF: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker ETN: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR \n",
      "1 Failed download:\n",
      "ERROR ['CEG']: Exception(\"CEG: Data doesn't exist for startDate = 1577854800, endDate = 1609390800\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to download data for ticker CEG: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker EL: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker RTX: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker PFE: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker WMB: list indices must be integers or slices, not str\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Failed to download data for ticker EMN: list indices must be integers or slices, not str\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2020,1,1)\n",
    "end_date = date(2020, 12, 31)\n",
    "\n",
    "# Define the ticker list\n",
    "tickers_list = random_stocks\n",
    "\n",
    "# Fetch the training data\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "#train_data = yf.download(tickers_list, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "\n",
    "train_data = \n",
    "for ticker in random_stocks:\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)['Adj Close']\n",
    "        train_data[ticker] = data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download data for ticker {ticker}: {e}\")\n",
    "\n",
    "# Print the available tickers\n",
    "#print(train_data.keys())\n",
    "#print(data.iloc[-1])\n",
    "# Print first 5 rows of the data\n",
    "#print(data.head())\n",
    "#print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d183721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download benchmark data - We can also use Buffet's Portfolio as a Benchmark\n",
    "spy_data = yf.download('SPY', start=start_date, end=end_date)['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab6352",
   "metadata": {},
   "source": [
    "## Applying Markowitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare historical price data for assets\n",
    "#historical_prices = pd.read_csv('historical_prices.csv', index_col=0, parse_dates=True)\n",
    "historical_prices = train_data\n",
    "\n",
    "\n",
    "# Calculate expected returns\n",
    "returns = expected_returns.mean_historical_return(historical_prices)\n",
    "#Add shrinkage here\n",
    "#https://pyportfolioopt.readthedocs.io/en/latest/RiskModels.html#pypfopt.risk_models.CovarianceShrinkage\n",
    "cov_matrix = risk_models.sample_cov(historical_prices)\n",
    "\n",
    "# Create an instance of EfficientFrontier\n",
    "#ef = EfficientFrontier(returns, cov_matrix,weight_bounds = (0,0.2))\n",
    "ef = EfficientFrontier(returns, cov_matrix, weight_bounds = (0,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b9905",
   "metadata": {},
   "source": [
    "# Efficient Frontier with random portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f4168",
   "metadata": {},
   "source": [
    "Maximise the Sharpe Ratio. The result is also referred to as the tangency portfolio, as it is the portfolio for which the capital market line is tangent to the efficient frontier.\n",
    "\n",
    "This is a convex optimization problem after making a certain variable substitution. See Cornuejols and Tutuncu (2006) for more.\n",
    "\n",
    "Because max_sharpe() makes a variable substitution, additional objectives may not work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ef_optimize = ef.deepcopy()\n",
    "plotting.plot_efficient_frontier(ef, ax=ax, show_assets=False)\n",
    "\n",
    "### Choosing Optimization Strategy (Comment out the other approach you want to use)\n",
    "\n",
    "### adding gamma for diversification - https://pyportfolioopt.readthedocs.io/en/latest/MeanVariance.html#l2-regularisation\n",
    "#ef_optimize.add_objective(objective_functions.L2_reg, gamma=1.5)\n",
    "\n",
    "\n",
    "### adding transaction costs objective function - https://github.com/robertmartin8/PyPortfolioOpt/blob/master/cookbook/3-Advanced-Mean-Variance-Optimisation.ipynb\n",
    "# Pretend that you started with a default-weight allocation\n",
    "#initial_weights = np.array([1/len(tickers_list)] * len(tickers_list))\n",
    "#ef_optimize.add_objective(objective_functions.transaction_cost, w_prev=initial_weights, k=0.001)\n",
    "\n",
    "#For Min Volatility\n",
    "#ef_optimize.min_volatility()\n",
    "\n",
    "#For Max Sharpe - \n",
    "#max_sharpe transforms the optimization problem so additional objectives eg. transaction costs, gamma may not work as expected.\n",
    "\n",
    "ef_optimize.max_sharpe()\n",
    "\n",
    "# Markowitz with Target Volatility\n",
    "\n",
    "#target_volatility = 0.2\n",
    "#ef_optimize.efficient_risk(target_volatility)\n",
    "\n",
    "# Find the tangency portfolio\n",
    "\n",
    "ret_tangent, std_tangent, _ = ef_optimize.portfolio_performance()\n",
    "ax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\n",
    "\n",
    "# Generate random portfolios\n",
    "n_samples = 100\n",
    "w = np.random.dirichlet(np.ones(ef.n_assets), n_samples)\n",
    "# Normalize weights to sum up to 1 - to make sure they lie within efficient frontier\n",
    "w = w / np.sum(w, axis=1, keepdims=True)  \n",
    "rets = w.dot(ef.expected_returns)\n",
    "stds = np.sqrt(np.diag(w @ ef.cov_matrix @ w.T))\n",
    "sharpes = rets / stds\n",
    "ax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"viridis_r\")\n",
    "\n",
    "# Output\n",
    "#ax.set_title(\"Efficient Frontier with random portfolios\")\n",
    "#ax.legend()\n",
    "ax.get_legend().remove()\n",
    "plt.tight_layout()\n",
    "#Saves the output file as a transparent image\n",
    "plt.savefig(\"ef_scatter.png\", dpi=200, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbf7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Weights - Max Sharpe\n",
    "cleaned_weights = ef_optimize.clean_weights()\n",
    "print(cleaned_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcce527",
   "metadata": {},
   "source": [
    "## In-Sample Portfolio Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701608c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to know the expected performance of the portfolio with optimal weights w\n",
    "ef_optimize.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75658ed",
   "metadata": {},
   "source": [
    "## Comparison with Benchmark Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Series to store portfolio returns\n",
    "portfolio_returns_1 = pd.Series()\n",
    "portfolio_returns_1.index.name = 'Date'\n",
    "\n",
    "# Extract unique years\n",
    "unique_years = historical_prices.index.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b70786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each year\n",
    "for year in unique_years:\n",
    "    \n",
    "    # Filter the DataFrame for the current year\n",
    "    current_year_prices = historical_prices[historical_prices.index.year == year]\n",
    "    # to get the last day of the previous year prices\n",
    "    previous_year_prices = historical_prices[historical_prices.index.year == year-1]\n",
    "    # Concatenate the last day of the previous year with the current year's data\n",
    "    # (to avoid NaN value for the first day of the year)\n",
    "    current_year_prices = pd.concat([previous_year_prices.tail(1), current_year_prices])\n",
    "    \n",
    "    # Perform operations on the current_year_prices\n",
    "    current_year_portfolio_returns = (current_year_prices.pct_change().dropna() * cleaned_weights).sum(axis=1)\n",
    "    \n",
    "    # Append current returns to the all_returns Series\n",
    "    portfolio_returns_1 = pd.concat([portfolio_returns_1, current_year_portfolio_returns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3e52e",
   "metadata": {},
   "source": [
    "### In sample graph comparison with Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602691ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio and benchmark returns\n",
    "portfolio_returns = portfolio_returns_1\n",
    "benchmark_returns = spy_data.pct_change().dropna()\n",
    "\n",
    "# Calculate portfolio and benchmark values\n",
    "#portfolio_values = (1 + portfolio_returns).cumprod() * 10000\n",
    "#benchmark_values = (1 + benchmark_returns).cumprod() * 10000\n",
    "\n",
    "# Plot the returns\n",
    "plt.figure(figsize=(10, 6), facecolor='none')\n",
    "plt.plot(portfolio_returns.cumsum(), label='Portfolio Returns')\n",
    "plt.plot(benchmark_returns.cumsum(), label='SPY Returns')\n",
    "plt.legend()\n",
    "#plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "#plt.title('Portfolio Returns vs SPY Returns')\n",
    "# Remove background grid lines\n",
    "plt.grid(visible=False)\n",
    "plt.savefig('portfolio_vs_spy.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4bf7a3",
   "metadata": {},
   "source": [
    "## Markowitz with Monthly Rebalancing keeping Original Weights Only\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19a4dd",
   "metadata": {},
   "source": [
    "## Markowitz with Monthly Rebalancing - With Original Weights Revising every 12 months\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888bb22",
   "metadata": {},
   "source": [
    "# Hierarchical Risk Parity\n",
    "HRP is a modern portfolio optimization method inspired by machine learning.\n",
    "\n",
    "The idea is that by examining the hierarchical structure of the market, we can better diversify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = expected_returns.returns_from_prices(historical_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53a0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hrp = HRPOpt(rets)\n",
    "hrp.optimize()\n",
    "weights = hrp.clean_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(weights).plot.pie(figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cdeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrp.portfolio_performance(verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407a7dc",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Plotting a dendrogram (tree diagram) based on the hierarchical structure of asset returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe858a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.plot_dendrogram(hrp); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edbf27",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad67f8a",
   "metadata": {},
   "source": [
    "#### Data Universe\n",
    "Training Data start_date = '2020-01-01'\n",
    "\n",
    "Training Data end_date = '2020-12-31'\n",
    "\n",
    "Testing Data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7e2cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(end_date)\n",
    "\n",
    "next_day = end_date + timedelta(days=1)\n",
    "\n",
    "# We invest on the next day using cleaned_weights\n",
    "\n",
    "print(next_day)\n",
    "\n",
    "# Now we keep the target weights same for 1 year\n",
    "\n",
    "next_year = end_date + relativedelta(years=1)\n",
    "\n",
    "print(next_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1100ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = yf.download(tickers_list, start=next_day, end=next_year)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_years = test_data.index.year.unique()\n",
    "testing_months = test_data.index.month.unique()\n",
    "\n",
    "print(testing_years, testing_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f5108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the discrete allocation of assets based on the optimal weights\n",
    "latest_prices = test_data.iloc[0]  # Latest prices for the assets - as on 1 Jan 2021\n",
    "da = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=10000)\n",
    "old_allocation, leftover = da.lp_portfolio(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f9c69",
   "metadata": {},
   "source": [
    "Optimal Allocation: {'AAPL': 16, 'AMD': 22, 'BABA': 3, 'GOOG': 23, 'RRC': 177, 'WMT': 14}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1099d3",
   "metadata": {},
   "source": [
    "Funds remaining: 99.28\n",
    "AAPL: allocated 0.190, desired 0.200\n",
    "AMD: allocated 0.214, desired 0.200\n",
    "BA: allocated 0.000, desired 0.000\n",
    "BABA: allocated 0.025, desired 0.075\n",
    "BAC: allocated 0.000, desired 0.000\n",
    "GE: allocated 0.000, desired 0.000\n",
    "GM: allocated 0.000, desired 0.000\n",
    "GOOG: allocated 0.225, desired 0.200\n",
    "JPM: allocated 0.000, desired 0.000\n",
    "MU: allocated 0.000, desired 0.000\n",
    "PFE: allocated 0.000, desired 0.000\n",
    "RRC: allocated 0.214, desired 0.125\n",
    "SBUX: allocated 0.000, desired 0.000\n",
    "T: allocated 0.000, desired 0.000\n",
    "UAA: allocated 0.000, desired 0.000\n",
    "WMT: allocated 0.131, desired 0.200\n",
    "XOM: allocated 0.000, desired 0.000\n",
    "Allocation has RMSE: 0.031\n",
    "Allocation: {'AAPL': 16, 'AMD': 22, 'BABA': 3, 'GOOG': 23, 'RRC': 177, 'WMT': 14}\n",
    "Leftover: 99.2767562866211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e940ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a202f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Optimal Allocation:\", old_allocation)\n",
    "print(\"Leftover:\", leftover)\n",
    "print (10000-leftover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba3cfa",
   "metadata": {},
   "source": [
    "### Now we calculate the portfolio value after one month and effective weights after one month - which is ratio of current assets vs Portfolio Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd2c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find first trading day of the next month\n",
    "\n",
    "current_month_prices = test_data[(test_data.index.year == 2021) & (test_data.index.month == 12)]\n",
    "\n",
    "current_month_prices = current_month_prices.sort_index()\n",
    "\n",
    "#pandas series with stocks name as index, prices are values and date as index name\n",
    "first_trading_day_prices = current_month_prices.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05945c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(first_trading_day_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(old_allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a646a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(first_trading_day_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139599be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Current Value of Each stock in allocated portfolio\n",
    "result = first_trading_day_prices * pd.Series(old_allocation)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ce588",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_portfolio_value = result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6392f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comparison with benchmark\n",
    "spy_test_data = yf.download('SPY', start=next_day, end=next_year)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a258d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(spy_data)\n",
    "\n",
    "10000/355.447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_effective_weights = result/new_portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_effective_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28f84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cleaned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce3776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordered_dict = cleaned_weights\n",
    "x1 = old_allocation\n",
    "\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8117e",
   "metadata": {},
   "source": [
    "## Comparison with Benchmark Chart - Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Series to store portfolio returns\n",
    "portfolio_test_returns = pd.Series()\n",
    "portfolio_test_returns.index.name = 'Date'\n",
    "\n",
    "# Extract unique years\n",
    "unique_years = test_data.index.year.unique()\n",
    "\n",
    "# Iterate through each year\n",
    "for year in unique_years:\n",
    "    \n",
    "    # Filter the DataFrame for the current year\n",
    "    current_year_prices = test_data[test_data.index.year == year]\n",
    "    # to get the last day of the previous year prices\n",
    "    previous_year_prices = test_data[test_data.index.year == year-1]\n",
    "    # Concatenate the last day of the previous year with the current year's data\n",
    "    # (to avoid NaN value for the first day of the year)\n",
    "    current_year_prices = pd.concat([previous_year_prices.tail(1), current_year_prices])\n",
    "    \n",
    "    # Perform operations on the current_year_prices\n",
    "    current_year_portfolio_returns = (current_year_prices.pct_change().dropna() * cleaned_weights).sum(axis=1)\n",
    "    \n",
    "    # Append current returns to the all_returns Series\n",
    "    portfolio_test_returns = pd.concat([portfolio_test_returns, current_year_portfolio_returns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b13a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio and benchmark returns\n",
    "portfolio_returns = portfolio_test_returns\n",
    "benchmark_returns = spy_test_data.pct_change().dropna()\n",
    "\n",
    "# Plot the returns\n",
    "plt.figure(figsize=(10, 6), facecolor='none')\n",
    "plt.plot(portfolio_returns.cumsum(), label='Portfolio Returns')\n",
    "plt.plot(benchmark_returns.cumsum(), label='SPY Returns')\n",
    "plt.legend()\n",
    "#plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "#plt.title('Portfolio Returns vs SPY Returns')\n",
    "# Remove background grid lines\n",
    "plt.grid(visible=False)\n",
    "plt.savefig('portfolio_vs_spy.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c849b",
   "metadata": {},
   "source": [
    "### working optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5b80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_value_constraints = {}\n",
    "for key, value in x1.items():\n",
    "    for index, (ordered_key, ordered_value) in enumerate(ordered_dict.items(), start=1):\n",
    "        if key == ordered_key:\n",
    "            new_key = int(index-1)\n",
    "            min_value_constraints[new_key] = value\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d578c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f948588",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_portfolio_value = 15000\n",
    "\n",
    "#### Instantiate the CustomDiscreteAllocation class\n",
    "da = CustomDiscreteAllocation(cleaned_weights, first_trading_day_prices, total_portfolio_value, min_value_constraints=min_value_constraints)\n",
    "\n",
    "#### Call the lp_portfolio method with the additional constraint\n",
    "new_allocation, leftover = da.lp_portfolio(reinvest=True, verbose=True)\n",
    "\n",
    "#### Print the allocation and leftover value\n",
    "print(\"Allocation:\", new_allocation)\n",
    "print(\"Leftover:\", leftover)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
